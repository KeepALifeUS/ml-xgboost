"""
Advanced Hyperparameter Tuning for XGBoost Models
==================================================

Comprehensive hyperparameter optimization system with multiple strategies
specifically optimized for XGBoost and time series prediction.

Features:
- Multi-objective optimization (performance vs speed)
- Distributed tuning capabilities
- Early stopping and pruning
- Custom objective functions for trading metrics
- Integration with cross-validation
- Parameter importance analysis
- Automated feature selection integration

Author: ML XGBoost Contributors
Version: 1.0.0
"""

import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Tuple, Any, Union, Callable
from dataclasses import dataclass, field
from abc import ABC, abstractmethod
from enum import Enum
import pickle
import joblib
import json
from pathlib import Path
import time
from datetime import datetime, timedelta
from concurrent.futures import ProcessPoolExecutor, as_completed
import threading

import xgboost as xgb
from sklearn.model_selection import cross_val_score, TimeSeriesSplit
from sklearn.metrics import (
    mean_squared_error, mean_absolute_error, r2_score,
    accuracy_score, f1_score, roc_auc_score
)
import optuna
from optuna.samplers import TPESampler, CmaEsSampler, RandomSampler
from optuna.pruners import MedianPruner, HyperbandPruner
from optuna.visualization import (
    plot_optimization_history, plot_param_importances,
    plot_slice, plot_contour
)
from scipy.optimize import differential_evolution, minimize
from skopt import gp_minimize, forest_minimize
from skopt.space import Real, Integer, Categorical
from skopt.utils import use_named_args

from loguru import logger
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn
from rich.console import Console
from rich.table import Table
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots


class OptimizationObjective(Enum):
    """–¶–µ–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤"""
    
    # Regression objectives
    MINIMIZE_RMSE = "minimize_rmse"
    MINIMIZE_MAE = "minimize_mae" 
    MAXIMIZE_R2 = "maximize_r2"
    MINIMIZE_MAPE = "minimize_mape"
    
    # Classification objectives
    MAXIMIZE_ACCURACY = "maximize_accuracy"
    MAXIMIZE_F1 = "maximize_f1"
    MAXIMIZE_AUC = "maximize_auc"
    MAXIMIZE_PRECISION = "maximize_precision"
    MAXIMIZE_RECALL = "maximize_recall"
    
    # Trading specific objectives
    MAXIMIZE_SHARPE_RATIO = "maximize_sharpe_ratio"
    MINIMIZE_DRAWDOWN = "minimize_drawdown"
    MAXIMIZE_PROFIT_FACTOR = "maximize_profit_factor"
    MAXIMIZE_WIN_RATE = "maximize_win_rate"
    MINIMIZE_VAR = "minimize_var"
    
    # Multi-objective
    PARETO_PERFORMANCE_SPEED = "pareto_performance_speed"
    PARETO_ACCURACY_COMPLEXITY = "pareto_accuracy_complexity"


class TuningStrategy(Enum):
    """–°—Ç—Ä–∞—Ç–µ–≥–∏–∏ –ø–æ–∏—Å–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
    OPTUNA_TPE = "optuna_tpe"  # Tree-structured Parzen Estimator
    OPTUNA_CMAES = "optuna_cmaes"  # CMA-ES
    BAYESIAN_GP = "bayesian_gp"  # Gaussian Process
    BAYESIAN_RF = "bayesian_rf"  # Random Forest
    RANDOM_SEARCH = "random_search"
    GRID_SEARCH = "grid_search"
    DIFFERENTIAL_EVOLUTION = "differential_evolution"
    GENETIC_ALGORITHM = "genetic_algorithm"


@dataclass
class ParameterSpace:
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    
    # Tree structure parameters
    n_estimators: Tuple[int, int] = (50, 2000)
    max_depth: Tuple[int, int] = (3, 15)
    min_child_weight: Tuple[int, int] = (1, 10)
    
    # Learning parameters
    learning_rate: Tuple[float, float] = (0.001, 0.3)
    gamma: Tuple[float, float] = (0.0, 10.0)
    
    # Regularization parameters
    reg_alpha: Tuple[float, float] = (0.0, 100.0)
    reg_lambda: Tuple[float, float] = (0.0, 100.0)
    
    # Sampling parameters
    subsample: Tuple[float, float] = (0.1, 1.0)
    colsample_bytree: Tuple[float, float] = (0.1, 1.0)
    colsample_bylevel: Tuple[float, float] = (0.1, 1.0)
    colsample_bynode: Tuple[float, float] = (0.1, 1.0)
    
    # Advanced parameters
    scale_pos_weight: Tuple[float, float] = (0.1, 10.0)
    max_delta_step: Tuple[int, int] = (0, 10)
    
    # Categorical parameters
    booster: List[str] = field(default_factory=lambda: ['gbtree', 'dart'])
    tree_method: List[str] = field(default_factory=lambda: ['auto', 'exact', 'approx', 'hist'])
    grow_policy: List[str] = field(default_factory=lambda: ['depthwise', 'lossguide'])
    
    def to_optuna_space(self, trial: optuna.Trial) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ Optuna search space"""
        
        params = {
            'n_estimators': trial.suggest_int('n_estimators', *self.n_estimators),
            'max_depth': trial.suggest_int('max_depth', *self.max_depth),
            'min_child_weight': trial.suggest_int('min_child_weight', *self.min_child_weight),
            'learning_rate': trial.suggest_float('learning_rate', *self.learning_rate, log=True),
            'gamma': trial.suggest_float('gamma', *self.gamma),
            'reg_alpha': trial.suggest_float('reg_alpha', *self.reg_alpha),
            'reg_lambda': trial.suggest_float('reg_lambda', *self.reg_lambda),
            'subsample': trial.suggest_float('subsample', *self.subsample),
            'colsample_bytree': trial.suggest_float('colsample_bytree', *self.colsample_bytree),
            'colsample_bylevel': trial.suggest_float('colsample_bylevel', *self.colsample_bylevel),
            'colsample_bynode': trial.suggest_float('colsample_bynode', *self.colsample_bynode),
            'booster': trial.suggest_categorical('booster', self.booster),
            'tree_method': trial.suggest_categorical('tree_method', self.tree_method),
        }
        
        # Conditional parameters
        if params['booster'] == 'gbtree':
            params['grow_policy'] = trial.suggest_categorical('grow_policy', self.grow_policy)
        
        return params
    
    def to_skopt_space(self) -> List[Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ scikit-optimize search space"""
        
        space = [
            Integer(*self.n_estimators, name='n_estimators'),
            Integer(*self.max_depth, name='max_depth'),
            Integer(*self.min_child_weight, name='min_child_weight'),
            Real(*self.learning_rate, prior='log-uniform', name='learning_rate'),
            Real(*self.gamma, name='gamma'),
            Real(*self.reg_alpha, name='reg_alpha'),
            Real(*self.reg_lambda, name='reg_lambda'),
            Real(*self.subsample, name='subsample'),
            Real(*self.colsample_bytree, name='colsample_bytree'),
            Real(*self.colsample_bylevel, name='colsample_bylevel'),
            Real(*self.colsample_bynode, name='colsample_bynode'),
            Categorical(self.booster, name='booster'),
            Categorical(self.tree_method, name='tree_method'),
        ]
        
        return space


@dataclass
class TuningConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è hyperparameter tuning"""
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    strategy: TuningStrategy = TuningStrategy.OPTUNA_TPE
    objective: OptimizationObjective = OptimizationObjective.MINIMIZE_RMSE
    n_trials: int = 100
    timeout_seconds: Optional[int] = 3600  # 1 hour
    
    # Cross-validation
    cv_folds: int = 5
    cv_strategy: str = "time_series"  # time_series, stratified, kfold
    scoring_metric: Optional[str] = None
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    n_jobs: int = -1
    enable_distributed: bool = False
    storage_url: Optional[str] = None  # For distributed Optuna
    study_name: Optional[str] = None
    
    # Early stopping –∏ pruning
    enable_pruning: bool = True
    pruning_patience: int = 10
    min_trials_for_pruning: int = 5
    
    # Parameter space
    parameter_space: Optional[ParameterSpace] = None
    
    # –ú–Ω–æ–≥–æ—Ü–µ–ª–µ–≤–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
    enable_multi_objective: bool = False
    secondary_objective: Optional[OptimizationObjective] = None
    objective_weights: Tuple[float, float] = (0.8, 0.2)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    save_intermediate_results: bool = True
    results_dir: str = "tuning_results"
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏
    enable_feature_selection: bool = False
    feature_selection_threshold: float = 0.01
    enable_ensemble_tuning: bool = False
    
    def __post_init__(self):
        if self.parameter_space is None:
            self.parameter_space = ParameterSpace()


@dataclass
class TuningResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç hyperparameter tuning"""
    
    # –õ—É—á—à–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    best_params: Dict[str, Any]
    best_score: float
    best_trial_number: int
    
    # –ò—Å—Ç–æ—Ä–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    optimization_history: List[Dict[str, Any]] = field(default_factory=list)
    parameter_importance: Dict[str, float] = field(default_factory=dict)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
    total_trials: int = 0
    successful_trials: int = 0
    pruned_trials: int = 0
    failed_trials: int = 0
    tuning_time: float = 0.0
    
    # Cross-validation —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    cv_scores: List[float] = field(default_factory=list)
    cv_mean: float = 0.0
    cv_std: float = 0.0
    
    # Multi-objective —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    pareto_front: Optional[List[Tuple[float, float]]] = None
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    timestamp: datetime = field(default_factory=datetime.now)
    config: Optional[TuningConfig] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å"""
        return {
            'best_params': self.best_params,
            'best_score': self.best_score,
            'best_trial_number': self.best_trial_number,
            'optimization_history': self.optimization_history,
            'parameter_importance': self.parameter_importance,
            'total_trials': self.total_trials,
            'successful_trials': self.successful_trials,
            'pruned_trials': self.pruned_trials,
            'failed_trials': self.failed_trials,
            'tuning_time': self.tuning_time,
            'cv_scores': self.cv_scores,
            'cv_mean': self.cv_mean,
            'cv_std': self.cv_std,
            'pareto_front': self.pareto_front,
            'timestamp': self.timestamp.isoformat(),
        }


class BaseHyperparameterTuner(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π—â–∏–∫–æ–≤ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ - enterprise pattern"""
    
    @abstractmethod
    def optimize(
        self,
        model_class: Any,
        X: pd.DataFrame,
        y: pd.Series,
        config: TuningConfig
    ) -> TuningResult:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        pass
    
    @abstractmethod
    def get_tuner_name(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –Ω–∞—Å—Ç—Ä–æ–π—â–∏–∫–∞"""
        pass


class HyperparameterTuner:
    """
    –ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ XGBoost –º–æ–¥–µ–ª–µ–π
    
    –†–µ–∞–ª–∏–∑—É–µ—Ç enterprise patterns:
    - –°—Ç—Ä–∞—Ç–µ–≥–∏—è –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    - –§–∞–±—Ä–∏—á–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–æ–≤
    - –ù–∞–±–ª—é–¥–∞—Ç–µ–ª—å –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
    - –ö–æ–º–∞–Ω–¥–∞ –ø–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –æ—Ç–º–µ–Ω—è–µ–º—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
    """
    
    def __init__(self, config: Optional[TuningConfig] = None):
        self.config = config or TuningConfig()
        
        # –í–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
        self.current_study_: Optional[Any] = None
        self.optimization_callbacks_: List[Callable] = []
        self.results_history_: List[TuningResult] = []
        
        # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
        self._objective_cache: Dict[str, float] = {}
        self._model_cache: Dict[str, Any] = {}
        
        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        self._stop_optimization = threading.Event()
        
        self.console = Console()
        self._setup_logging()
    
    def _setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        logger.add(
            f"logs/hyperparameter_tuning_{datetime.now():%Y%m%d}.log",
            rotation="daily",
            retention="30 days",
            level="INFO"
        )
    
    def add_callback(self, callback: Callable[[optuna.Trial], None]):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ callback —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        self.optimization_callbacks_.append(callback)
    
    def optimize(
        self,
        model_class: Any,
        X: pd.DataFrame,
        y: pd.Series,
        X_val: Optional[pd.DataFrame] = None,
        y_val: Optional[pd.Series] = None
    ) -> TuningResult:
        """
        –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        
        Args:
            model_class: –ö–ª–∞—Å—Å XGBoost –º–æ–¥–µ–ª–∏
            X: –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            y: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            X_val: –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            y_val: –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è —Ü–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
        """
        
        start_time = time.time()
        logger.info(f"üöÄ –ù–∞—á–∞–ª–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {self.config.strategy.value}")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results_dir = Path(self.config.results_dir)
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ objective function
        def objective(trial: optuna.Trial) -> float:
            return self._objective_function(
                trial, model_class, X, y, X_val, y_val
            )
        
        # –í—ã–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        if self.config.strategy == TuningStrategy.OPTUNA_TPE:
            result = self._optimize_with_optuna(objective, TPESampler())
        elif self.config.strategy == TuningStrategy.OPTUNA_CMAES:
            result = self._optimize_with_optuna(objective, CmaEsSampler())
        elif self.config.strategy == TuningStrategy.BAYESIAN_GP:
            result = self._optimize_with_skopt(model_class, X, y, X_val, y_val, 'gp')
        elif self.config.strategy == TuningStrategy.BAYESIAN_RF:
            result = self._optimize_with_skopt(model_class, X, y, X_val, y_val, 'rf')
        elif self.config.strategy == TuningStrategy.RANDOM_SEARCH:
            result = self._optimize_with_random_search(model_class, X, y, X_val, y_val)
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è: {self.config.strategy}")
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        result.tuning_time = time.time() - start_time
        result.config = self.config
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if self.config.save_intermediate_results:
            self._save_results(result, results_dir)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
        self.results_history_.append(result)
        
        logger.info(f"‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {result.tuning_time:.2f}—Å")
        
        # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self._display_results(result)
        
        return result
    
    def _objective_function(
        self,
        trial: optuna.Trial,
        model_class: Any,
        X: pd.DataFrame,
        y: pd.Series,
        X_val: Optional[pd.DataFrame],
        y_val: Optional[pd.Series]
    ) -> float:
        """
        Objective function –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        
        Args:
            trial: Optuna trial –æ–±—ä–µ–∫—Ç
            model_class: –ö–ª–∞—Å—Å –º–æ–¥–µ–ª–∏
            X, y: –û–±—É—á–∞—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
            X_val, y_val: –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        
        try:
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ trial
            params = self.config.parameter_space.to_optuna_space(trial)
            
            # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            params_key = str(sorted(params.items()))
            if params_key in self._objective_cache:
                return self._objective_cache[params_key]
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
            model = model_class(**params, random_state=42, n_jobs=1)
            
            # Cross-validation –∏–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–º –Ω–∞–±–æ—Ä–µ
            if X_val is not None and y_val is not None:
                # –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–º –Ω–∞–±–æ—Ä–µ
                model.fit(X, y)
                predictions = model.predict(X_val)
                score = self._calculate_score(y_val, predictions)
            else:
                # Cross-validation
                scores = self._cross_validate_model(model, X, y)
                score = np.mean(scores)
            
            # –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            self._objective_cache[params_key] = score
            
            # Callback –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            for callback in self.optimization_callbacks_:
                callback(trial)
            
            # Pruning –¥–ª—è —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –Ω–µ–ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö trials
            if self.config.enable_pruning and trial.should_prune():
                raise optuna.TrialPruned()
            
            return score
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ trial {trial.number}: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–ª–æ—Ö–æ–π —Å–∫–æ—Ä –¥–ª—è –Ω–µ—É—Å–ø–µ—à–Ω—ã—Ö trials
            if self._is_minimization_objective():
                return float('inf')
            else:
                return float('-inf')
    
    def _optimize_with_optuna(
        self,
        objective: Callable,
        sampler: optuna.samplers.BaseSampler
    ) -> TuningResult:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Optuna"""
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ pruner
        if self.config.enable_pruning:
            pruner = MedianPruner(
                n_startup_trials=self.config.min_trials_for_pruning,
                n_warmup_steps=self.config.pruning_patience
            )
        else:
            pruner = optuna.pruners.NopPruner()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ study
        direction = "minimize" if self._is_minimization_objective() else "maximize"
        
        if self.config.storage_url and self.config.study_name:
            # Distributed optimization
            study = optuna.create_study(
                direction=direction,
                sampler=sampler,
                pruner=pruner,
                storage=self.config.storage_url,
                study_name=self.config.study_name,
                load_if_exists=True
            )
        else:
            # Local optimization
            study = optuna.create_study(
                direction=direction,
                sampler=sampler,
                pruner=pruner
            )
        
        self.current_study_ = study
        
        # Progress tracking
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        ) as progress:
            
            task = progress.add_task("–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤...", total=self.config.n_trials)
            
            def progress_callback(study, trial):
                progress.update(task, advance=1)
                progress.update(
                    task,
                    description=f"Trial {trial.number}/{self.config.n_trials} | "
                               f"Best: {study.best_value:.4f}"
                )
            
            study.optimize(
                objective,
                n_trials=self.config.n_trials,
                timeout=self.config.timeout_seconds,
                callbacks=[progress_callback],
                n_jobs=self.config.n_jobs if not self.config.enable_distributed else 1,
                show_progress_bar=False
            )
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result = TuningResult(
            best_params=study.best_params,
            best_score=study.best_value,
            best_trial_number=study.best_trial.number,
            total_trials=len(study.trials),
            successful_trials=len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),
            pruned_trials=len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),
            failed_trials=len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL]),
        )
        
        # –ò—Å—Ç–æ—Ä–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        result.optimization_history = [
            {
                'trial_number': trial.number,
                'value': trial.value,
                'params': trial.params,
                'state': trial.state.name,
                'datetime': trial.datetime_start.isoformat() if trial.datetime_start else None,
                'duration': (trial.datetime_complete - trial.datetime_start).total_seconds() 
                           if trial.datetime_complete and trial.datetime_start else None,
            }
            for trial in study.trials
        ]
        
        # Parameter importance
        try:
            importance = optuna.importance.get_param_importances(study)
            result.parameter_importance = importance
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã—á–∏—Å–ª–∏—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {e}")
        
        return result
    
    def _optimize_with_skopt(
        self,
        model_class: Any,
        X: pd.DataFrame,
        y: pd.Series,
        X_val: Optional[pd.DataFrame],
        y_val: Optional[pd.Series],
        base_estimator: str = 'gp'
    ) -> TuningResult:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º scikit-optimize"""
        
        space = self.config.parameter_space.to_skopt_space()
        
        @use_named_args(space)
        def skopt_objective(**params):
            try:
                model = model_class(**params, random_state=42, n_jobs=1)
                
                if X_val is not None and y_val is not None:
                    model.fit(X, y)
                    predictions = model.predict(X_val)
                    score = self._calculate_score(y_val, predictions)
                else:
                    scores = self._cross_validate_model(model, X, y)
                    score = np.mean(scores)
                
                return -score if not self._is_minimization_objective() else score
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ skopt objective: {e}")
                return 1e10 if self._is_minimization_objective() else -1e10
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
        if base_estimator == 'gp':
            skopt_result = gp_minimize(
                func=skopt_objective,
                dimensions=space,
                n_calls=self.config.n_trials,
                n_jobs=self.config.n_jobs,
                random_state=42
            )
        else:  # Random Forest
            skopt_result = forest_minimize(
                func=skopt_objective,
                dimensions=space,
                n_calls=self.config.n_trials,
                n_jobs=self.config.n_jobs,
                random_state=42
            )
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        best_params = {}
        for i, param_name in enumerate([dim.name for dim in space]):
            best_params[param_name] = skopt_result.x[i]
        
        best_score = -skopt_result.fun if not self._is_minimization_objective() else skopt_result.fun
        
        result = TuningResult(
            best_params=best_params,
            best_score=best_score,
            best_trial_number=0,  # skopt doesn't have trial numbers
            total_trials=len(skopt_result.func_vals),
            successful_trials=len(skopt_result.func_vals),
            pruned_trials=0,
            failed_trials=0,
        )
        
        # –ò—Å—Ç–æ—Ä–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        result.optimization_history = [
            {
                'trial_number': i,
                'value': -val if not self._is_minimization_objective() else val,
                'params': dict(zip([dim.name for dim in space], x)),
            }
            for i, (x, val) in enumerate(zip(skopt_result.x_iters, skopt_result.func_vals))
        ]
        
        return result
    
    def _optimize_with_random_search(
        self,
        model_class: Any,
        X: pd.DataFrame,
        y: pd.Series,
        X_val: Optional[pd.DataFrame],
        y_val: Optional[pd.Series]
    ) -> TuningResult:
        """–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã–º –ø–æ–∏—Å–∫–æ–º"""
        
        best_score = float('inf') if self._is_minimization_objective() else float('-inf')
        best_params = {}
        best_trial_number = 0
        history = []
        
        param_space = self.config.parameter_space
        
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        ) as progress:
            
            task = progress.add_task("Random Search...", total=self.config.n_trials)
            
            for trial_num in range(self.config.n_trials):
                try:
                    # –°–ª—É—á–∞–π–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                    params = {
                        'n_estimators': np.random.randint(*param_space.n_estimators),
                        'max_depth': np.random.randint(*param_space.max_depth),
                        'min_child_weight': np.random.randint(*param_space.min_child_weight),
                        'learning_rate': np.random.uniform(*param_space.learning_rate),
                        'gamma': np.random.uniform(*param_space.gamma),
                        'reg_alpha': np.random.uniform(*param_space.reg_alpha),
                        'reg_lambda': np.random.uniform(*param_space.reg_lambda),
                        'subsample': np.random.uniform(*param_space.subsample),
                        'colsample_bytree': np.random.uniform(*param_space.colsample_bytree),
                        'booster': np.random.choice(param_space.booster),
                        'tree_method': np.random.choice(param_space.tree_method),
                    }
                    
                    # –û—Ü–µ–Ω–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
                    model = model_class(**params, random_state=42, n_jobs=1)
                    
                    if X_val is not None and y_val is not None:
                        model.fit(X, y)
                        predictions = model.predict(X_val)
                        score = self._calculate_score(y_val, predictions)
                    else:
                        scores = self._cross_validate_model(model, X, y)
                        score = np.mean(scores)
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ª—É—á—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    if self._is_better_score(score, best_score):
                        best_score = score
                        best_params = params
                        best_trial_number = trial_num
                    
                    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é
                    history.append({
                        'trial_number': trial_num,
                        'value': score,
                        'params': params,
                        'state': 'COMPLETE',
                    })
                    
                    progress.update(
                        task,
                        advance=1,
                        description=f"Trial {trial_num}/{self.config.n_trials} | "
                                   f"Best: {best_score:.4f}"
                    )
                
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ random search trial {trial_num}: {e}")
                    history.append({
                        'trial_number': trial_num,
                        'value': None,
                        'params': None,
                        'state': 'FAIL',
                    })
        
        result = TuningResult(
            best_params=best_params,
            best_score=best_score,
            best_trial_number=best_trial_number,
            total_trials=len(history),
            successful_trials=len([h for h in history if h['state'] == 'COMPLETE']),
            pruned_trials=0,
            failed_trials=len([h for h in history if h['state'] == 'FAIL']),
            optimization_history=history,
        )
        
        return result
    
    def _cross_validate_model(
        self,
        model: Any,
        X: pd.DataFrame,
        y: pd.Series
    ) -> List[float]:
        """Cross-validation –º–æ–¥–µ–ª–∏"""
        
        # –í—ã–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ CV
        if self.config.cv_strategy == "time_series":
            cv = TimeSeriesSplit(n_splits=self.config.cv_folds)
        else:
            cv = self.config.cv_folds
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ scoring metric
        if self.config.scoring_metric:
            scoring = self.config.scoring_metric
        else:
            scoring = self._get_default_scoring_metric()
        
        # Cross-validation
        scores = cross_val_score(
            model, X, y,
            cv=cv,
            scoring=scoring,
            n_jobs=1,  # –ß—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
            error_score='raise'
        )
        
        return scores.tolist()
    
    def _calculate_score(
        self,
        y_true: pd.Series,
        y_pred: np.ndarray
    ) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å–∫–æ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ objective"""
        
        if self.config.objective == OptimizationObjective.MINIMIZE_RMSE:
            return np.sqrt(mean_squared_error(y_true, y_pred))
        elif self.config.objective == OptimizationObjective.MINIMIZE_MAE:
            return mean_absolute_error(y_true, y_pred)
        elif self.config.objective == OptimizationObjective.MAXIMIZE_R2:
            return r2_score(y_true, y_pred)
        elif self.config.objective == OptimizationObjective.MAXIMIZE_ACCURACY:
            return accuracy_score(y_true, y_pred)
        elif self.config.objective == OptimizationObjective.MAXIMIZE_F1:
            return f1_score(y_true, y_pred, average='weighted')
        elif self.config.objective == OptimizationObjective.MAXIMIZE_SHARPE_RATIO:
            returns = pd.Series(y_pred).pct_change().fillna(0)
            return returns.mean() / returns.std() if returns.std() != 0 else 0
        else:
            # Fallback –∫ RMSE
            return np.sqrt(mean_squared_error(y_true, y_pred))
    
    def _is_minimization_objective(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ objective –º–∏–Ω–∏–º–∏–∑–∞—Ü–∏–æ–Ω–Ω–æ–π"""
        minimization_objectives = {
            OptimizationObjective.MINIMIZE_RMSE,
            OptimizationObjective.MINIMIZE_MAE,
            OptimizationObjective.MINIMIZE_MAPE,
            OptimizationObjective.MINIMIZE_DRAWDOWN,
            OptimizationObjective.MINIMIZE_VAR,
        }
        return self.config.objective in minimization_objectives
    
    def _is_better_score(self, new_score: float, current_best: float) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞, –ª—É—á—à–µ –ª–∏ –Ω–æ–≤—ã–π —Å–∫–æ—Ä"""
        if self._is_minimization_objective():
            return new_score < current_best
        else:
            return new_score > current_best
    
    def _get_default_scoring_metric(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è CV"""
        
        if self.config.objective in [
            OptimizationObjective.MINIMIZE_RMSE,
            OptimizationObjective.MINIMIZE_MAE,
            OptimizationObjective.MAXIMIZE_R2
        ]:
            return 'neg_mean_squared_error'
        elif self.config.objective in [
            OptimizationObjective.MAXIMIZE_ACCURACY,
            OptimizationObjective.MAXIMIZE_F1
        ]:
            return 'accuracy'
        else:
            return 'neg_mean_squared_error'
    
    def _display_results(self, result: TuningResult):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        
        table = Table(title=f"üéØ –†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–ò –ì–ò–ü–ï–†–ü–ê–†–ê–ú–ï–¢–†–û–í")
        table.add_column("–ú–µ—Ç—Ä–∏–∫–∞", style="cyan")
        table.add_column("–ó–Ω–∞—á–µ–Ω–∏–µ", style="green")
        
        table.add_row("–õ—É—á—à–∏–π —Å–∫–æ—Ä", f"{result.best_score:.6f}")
        table.add_row("–õ—É—á—à–∏–π trial", str(result.best_trial_number))
        table.add_row("–í—Å–µ–≥–æ trials", str(result.total_trials))
        table.add_row("–£—Å–ø–µ—à–Ω—ã—Ö", str(result.successful_trials))
        table.add_row("–û–±—Ä–µ–∑–∞–Ω–Ω—ã—Ö", str(result.pruned_trials))
        table.add_row("–ù–µ—É–¥–∞—á–Ω—ã—Ö", str(result.failed_trials))
        table.add_row("–í—Ä–µ–º—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏", f"{result.tuning_time:.2f}—Å")
        
        self.console.print(table)
        
        # –¢–æ–ø-5 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
        if result.parameter_importance:
            importance_table = Table(title="üìä –í–ê–ñ–ù–û–°–¢–¨ –ü–ê–†–ê–ú–ï–¢–†–û–í")
            importance_table.add_column("–ü–∞—Ä–∞–º–µ—Ç—Ä", style="cyan")
            importance_table.add_column("–í–∞–∂–Ω–æ—Å—Ç—å", style="green")
            
            sorted_importance = sorted(
                result.parameter_importance.items(),
                key=lambda x: x[1],
                reverse=True
            )[:5]
            
            for param, importance in sorted_importance:
                importance_table.add_row(param, f"{importance:.4f}")
            
            self.console.print(importance_table)
    
    def _save_results(self, result: TuningResult, results_dir: Path):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results_file = results_dir / f"tuning_results_{timestamp}.json"
        with open(results_file, 'w') as f:
            json.dump(result.to_dict(), f, indent=2, default=str)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –æ—Ç–¥–µ–ª—å–Ω–æ
        params_file = results_dir / f"best_params_{timestamp}.json"
        with open(params_file, 'w') as f:
            json.dump(result.best_params, f, indent=2)
        
        logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {results_dir}")
    
    def plot_optimization_history(
        self,
        result: TuningResult,
        save_path: Optional[str] = None
    ):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        
        if not result.optimization_history:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –∏—Å—Ç–æ—Ä–∏–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞")
            return
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        trial_numbers = []
        values = []
        
        for entry in result.optimization_history:
            if entry.get('value') is not None:
                trial_numbers.append(entry['trial_number'])
                values.append(entry['value'])
        
        if not trial_numbers:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç —É—Å–ø–µ—à–Ω—ã—Ö trials –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞")
            return
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
        
        # –ò—Å—Ç–æ—Ä–∏—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        ax1.plot(trial_numbers, values, 'b-', alpha=0.6, label='Trial values')
        
        # –õ—É—á—à–∏–π —Å–∫–æ—Ä –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ
        best_so_far = []
        current_best = float('inf') if self._is_minimization_objective() else float('-inf')
        
        for value in values:
            if self._is_better_score(value, current_best):
                current_best = value
            best_so_far.append(current_best)
        
        ax1.plot(trial_numbers, best_so_far, 'r-', linewidth=2, label='Best so far')
        ax1.set_xlabel('Trial Number')
        ax1.set_ylabel('Objective Value')
        ax1.set_title('Optimization History')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∫–æ—Ä–æ–≤
        ax2.hist(values, bins=30, alpha=0.7, edgecolor='black')
        ax2.axvline(result.best_score, color='red', linestyle='--', 
                   label=f'Best Score: {result.best_score:.4f}')
        ax2.set_xlabel('Objective Value')
        ax2.set_ylabel('Frequency')
        ax2.set_title('Distribution of Trial Scores')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
        else:
            plt.show()
    
    def plot_parameter_importance(
        self,
        result: TuningResult,
        save_path: Optional[str] = None
    ):
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤"""
        
        if not result.parameter_importance:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
            return
        
        # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
        sorted_importance = sorted(
            result.parameter_importance.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        params, importance = zip(*sorted_importance)
        
        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞
        fig, ax = plt.subplots(figsize=(10, 6))
        
        bars = ax.barh(range(len(params)), importance, color='skyblue', alpha=0.7)
        ax.set_yticks(range(len(params)))
        ax.set_yticklabels(params)
        ax.set_xlabel('Parameter Importance')
        ax.set_title('Hyperparameter Importance')
        ax.grid(True, alpha=0.3)
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏–π –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for i, bar in enumerate(bars):
            width = bar.get_width()
            ax.text(width, bar.get_y() + bar.get_height()/2,
                   f'{width:.3f}', ha='left', va='center')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            logger.info(f"üìä –ì—Ä–∞—Ñ–∏–∫ –≤–∞–∂–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {save_path}")
        else:
            plt.show()
    
    def get_best_model(
        self,
        model_class: Any,
        result: TuningResult
    ) -> Any:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
        
        return model_class(**result.best_params, random_state=42)
    
    def resume_optimization(
        self,
        study_name: str,
        storage_url: str,
        additional_trials: int = 50
    ) -> TuningResult:
        """–í–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–Ω–æ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ study
        study = optuna.load_study(
            study_name=study_name,
            storage=storage_url
        )
        
        logger.info(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ study —Å {len(study.trials)} trials")
        
        # –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        def objective(trial):
            # –ó–¥–µ—Å—å –Ω—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é objective function
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —ç—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ
            raise NotImplementedError("–î–ª—è resume –Ω—É–∂–Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–∞—è objective function")
        
        study.optimize(objective, n_trials=additional_trials)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result = TuningResult(
            best_params=study.best_params,
            best_score=study.best_value,
            best_trial_number=study.best_trial.number,
            total_trials=len(study.trials),
        )
        
        return result


if __name__ == "__main__":
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    logger.info("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Hyperparameter Tuner...")
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
    np.random.seed(42)
    n_samples = 1000
    n_features = 10
    
    X = pd.DataFrame(
        np.random.randn(n_samples, n_features),
        columns=[f'feature_{i}' for i in range(n_features)]
    )
    
    # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
    y = pd.Series(
        X.iloc[:, :3].sum(axis=1) + 0.1 * np.random.randn(n_samples),
        name='target'
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = TuningConfig(
        strategy=TuningStrategy.OPTUNA_TPE,
        objective=OptimizationObjective.MINIMIZE_RMSE,
        n_trials=20,  # –ú–∞–ª–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        cv_folds=3,
        enable_pruning=True
    )
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Éner
    tuner = HyperparameterTuner(config)
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π XGBRegressor –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
    from sklearn.ensemble import RandomForestRegressor  # –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    
    class MockXGBRegressor:
        def __init__(self, **kwargs):
            self.params = kwargs
        
        def fit(self, X, y):
            pass
        
        def predict(self, X):
            return np.random.randn(len(X))
    
    # result = tuner.optimize(MockXGBRegressor, X, y)
    
    logger.info("‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Hyperparameter Tuner –≥–æ—Ç–æ–≤–æ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!")